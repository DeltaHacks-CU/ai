{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6zp9ylLvauO",
        "outputId": "45791ad1-7787-4b62-c30d-730931cbfe07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [00:00<00:00, 3104.35it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 1878.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 26s 2s/step - loss: 5.8004 - accuracy: 0.4746\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.6908 - accuracy: 0.5593\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.7074 - accuracy: 0.5932\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.6000 - accuracy: 0.7119\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.4686 - accuracy: 0.8136\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 29s 2s/step - loss: 0.2607 - accuracy: 0.9153\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 25s 2s/step - loss: 0.0071 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "categories = [\"FoodTrucks\", \"NotFoodTruck\"]\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in categories:\n",
        "        class_num = categories.index(category) \n",
        "        path = os.path.join(\"/tmp/Data/\", category)\n",
        "\n",
        "        for img in tqdm(os.listdir(path)): \n",
        "            img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)\n",
        "            new_array = cv2.resize(img_array, (150, 150))\n",
        "            training_data.append([new_array, class_num])\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, 150, 150, 1)\n",
        "\n",
        "X = X/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape = X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "y = np.array(y)\n",
        "\n",
        "model.fit(X, y, batch_size=5, epochs=10)\n",
        "# model.summary()\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# model.fit(X_train, y_train, batch_size=10, epochs=1)\n",
        "\n",
        "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "# print('Test accuracy:', test_acc)\n",
        "\n",
        "# model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4_o1-RaHr0H"
      },
      "outputs": [],
      "source": [
        "# This part of the code is for testing the model\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "\n",
        "def classify_image(image_path):\n",
        "    # read the image\n",
        "    img = cv2.imread(image_path)\n",
        "    # convert to grayscale\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # resize to 150x150\n",
        "    resized_img = cv2.resize(gray_img, (150, 150))\n",
        "    # normalize the image\n",
        "    resized_img = resized_img/255.0\n",
        "    # reshape the image to match the model input shape\n",
        "    resized_img = resized_img.reshape(-1, 150, 150, 1)\n",
        "    # use the model to predict the class of the image\n",
        "    prediction = model.predict(resized_img)\n",
        "    # interpret the prediction\n",
        "    if prediction[0][0] > 0.5:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def test_images(folder_path):\n",
        "    correct_count = 0\n",
        "    total_count = 0\n",
        "    for img in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, img)\n",
        "        expected_output = not (\"not\" in img)\n",
        "        output = classify_image(file_path)\n",
        "        if output == expected_output:\n",
        "            correct_count += 1\n",
        "        total_count += 1\n",
        "    \n",
        "    accuracy = correct_count / total_count\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "\n",
        "#This is an example of how you could use these functions to test the model and make sure its predictions are correct\n",
        "folder_path = \"/tmp/Data/Test\"\n",
        "test_images(folder_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
